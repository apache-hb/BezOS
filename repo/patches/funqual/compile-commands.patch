diff --git a/parse.py b/parse.py
index 75e8535..9180162 100755
--- a/parse.py
+++ b/parse.py
@@ -10,7 +10,9 @@ from collections import defaultdict
 from optparse import OptionParser
 import rules
 import scrapers
+import os
 import ast_helpers
+from clang import cindex
 from call_tree import build_call_tree, merge_call_trees
 from type_augmentor import augment_types
 from assignment_checker import check_assignments
@@ -19,7 +21,7 @@ from rule_checker import check_rules
 
 logging.basicConfig( filename="dbg_output", filemode="w", level=logging.DEBUG )
 
-def scrape_all_files( files, ext_types, options ):
+def scrape_all_files( files, ext_types, options, compdb: cindex.CompilationDatabase, compdb_path: str):
     call_subtrees = []
     override_subtrees = []
     cursor_subsets = []
@@ -29,23 +31,94 @@ def scrape_all_files( files, ext_types, options ):
 
     tu_time = 0.0
     start_time = time.time()
+    index = cindex.Index.create()
 
-    for fname in files:
+    parsed = set()
+
+    files = [ os.path.abspath( f ) for f in files ]
+
+    for fname in compdb.getAllCompileCommands():
         overrideScraper = scrapers.Overrides()
         cursorScraper = scrapers.FunctionCursors()
         funcTypeScraper = scrapers.FunctionQualifiers()
         funPtrTypeScraper = scrapers.FunctionPointers()
         assScraper = scrapers.FunPtrAssignments()
 
+        # make path canonical
+        filename = os.path.join(compdb_path, fname.filename)
+        # now make it absolute
+        filename = os.path.abspath(filename)
+
+        if filename in parsed:
+            continue
+
+        if filename not in files:
+            continue
+
+        parsed.add( filename )
+
+        if 'sources/kernel' not in filename:
+            print( "Skipping " + filename )
+            continue
+
+        if 'kernel/test' in filename:
+            print( "Skipping " + filename )
+            continue
+
+        if 'subprojects' in filename:
+            print( "Skipping " + filename )
+            continue
+
+        args1 = list( fname.arguments )
+
+        if 'clang' in args1[0]:
+            args1 = args1[1:]
+        if args1[-2] == '-c':
+            args1 = args1[:-2]
+
+        args = [ '-std=c++26', '--driver-mode=g++' ]
+        for arg in args1:
+            if arg.startswith('-I'):
+                path = arg[2:]
+                path = os.path.abspath(os.path.join(compdb_path, path))
+                args.append('-I' + path)
+            elif arg.startswith('-D'):
+                args.append(arg)
+
+        args.append('-I/usr/local/lib/clang/21/include')
+        args.append('-I/usr/local/include/c++/14.2.0')
+        args.append('-I/usr/local/include/c++/14.2.0/x86_64-pc-linux-gnu')
+
+        if filename.endswith('.S'):
+            continue
+
+        print( "Parsing " + filename )
         pre_tu_time = time.time()
-        target = ast_helpers.get_translation_unit( fname, options )
+        try:
+
+            target = index.parse(filename, options=cindex.TranslationUnit.PARSE_DETAILED_PROCESSING_RECORD, args=args)
+        except Exception as e:
+            print( "\nFailed to parse " + filename + " with args: " + str(' '.join(args)) )
+            raise
+
+        if target is None:
+            print( "\nFailed to parse " + filename + " with args: " + str(' '.join(args)) )
+            return
+
+        if target.diagnostics:
+            for diag in target.diagnostics:
+                if diag.severity >= cindex.Diagnostic.Error:
+                    print( "\nParsing errors for " + filename + " with args: " + str(' '.join(args)) )
+                    for diag in target.diagnostics:
+                        print( "\t" + str( diag ) )
+                    return
 
         logging.info( "Translation unit: " + str( target.spelling ) )
         #ast_helpers.dump_ast( target.cursor, lambda x: logging.debug(x) )
 
         tu_time += time.time() - pre_tu_time
 
-        scrapers.run_scrapers( target.cursor, 
+        scrapers.run_scrapers( target.cursor,
                 [ overrideScraper, cursorScraper,
                   funcTypeScraper, funPtrTypeScraper,
                   assScraper ] )
@@ -84,14 +157,14 @@ def scrape_all_files( files, ext_types, options ):
 
     standard_funcs = set( [ key for key in func_types.keys() ] )
 
-    all_func_types = scrapers.merge_disjoint_dicts( 
+    all_func_types = scrapers.merge_disjoint_dicts(
             [ aug_func_types, funcptr_types ] )
 
     end_time = time.time()
 
     if options.show_time:
         print( "time to parse: {:0.5f} seconds".format( tu_time ) )
-        print( "time to scrape stuff: {:0.5f} seconds".format( 
+        print( "time to scrape stuff: {:0.5f} seconds".format(
                end_time - start_time - tu_time ) )
         print( "time to infer indirect type: {:0.5f} seconds".format(
                post_augment_time - pre_augment_time ) )
@@ -103,13 +176,15 @@ def get_violations( files, tagsfile, options ):
 
     ext_types, type_rules = rules.parse_rules_file( tagsfile )
 
+    compdb = cindex.CompilationDatabase.fromDirectory(options.compile_commands)
+
     pre_file_parse = time.time()
     ( call_tree,
       all_func_types,
       cursors,
       assignments,
       standard_funcs,
-      overrides ) = scrape_all_files( files, ext_types, options )
+      overrides ) = scrape_all_files( files, ext_types, options, compdb, options.compile_commands )
     post_file_parse = time.time()
 
     rule_violations = check_rules(
@@ -178,6 +253,12 @@ def parse_args():
                        help="Output execution time for different phases of prgm",
                        default=False )
 
+    parser.add_option( "--compile-commands", dest="compile_commands",
+                       help=( "Specify the compile_commands.json file to use.  "
+                              + "If not specified, the program will search for "
+                              + "it in the current directory." ),
+                       metavar="FILE", default=None )
+
     ( options, files ) = parser.parse_args()
 
     if len( sys.argv ) == 1:
diff --git a/scrapers.py b/scrapers.py
index 5a196b5..12a20fe 100755
--- a/scrapers.py
+++ b/scrapers.py
@@ -46,6 +46,9 @@ def merge_disjoint_dicts( dicts ):
 
     for mapping in dicts:
         for key, value in mapping.items():
+            if not key:
+                continue
+
             if key in result:
                 raise Exception(
                         "key `{}` defined in two dictionaries".format(
@@ -152,7 +155,7 @@ class FunctionCursors:
 
     def scrape( self, trav ):
         """
-        Given a node in a tu, scrape a mapping of function usr to the 
+        Given a node in a tu, scrape a mapping of function usr to the
         cannonical cursor (we need to be able to retrieve the cursor later
         for error reporting)
         """
@@ -185,7 +188,7 @@ class Overrides:
 
     def scrape( self, trav ):
         """
-        Scrape a translation unit and generate a mapping of methods to the 
+        Scrape a translation unit and generate a mapping of methods to the
         methods that override them
         """
         if trav.kind == CursorKind.CXX_METHOD:
